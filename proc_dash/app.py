"""
Constructs Dash app for viewing and filtering statuses of processing pipelines for a given dataset.
App accepts and parses a user-uploaded bagel.csv file (assumed to be generated by mr_proc) as input.
"""

import base64
import io
import json
from pathlib import Path
from typing import Optional, Tuple

import dash_bootstrap_components as dbc
import pandas as pd
from dash.dependencies import Input, Output, State
from dash.exceptions import PreventUpdate

from dash import Dash, ctx, dash_table, dcc, html

SCHEMAS_PATH = Path(__file__).absolute().parent.parent / "schemas"


def get_required_bagel_columns() -> list:
    """Returns names of required columns from the bagel schema."""
    with open(SCHEMAS_PATH / "bagel_schema.json", "r") as file:
        schema = json.load(file)

    required_columns = []
    for col_category, cols in schema.items():
        for col, props in cols.items():
            if props["IsRequired"]:
                required_columns.append(col)

    return required_columns


# TODO: When possible values per column have been finalized (waiting on mr_proc),
# validate that each column only has acceptable values
def check_required_columns(bagel: pd.DataFrame):
    """Returns error if required columns in bagel schema are missing."""
    missing_req_columns = set(get_required_bagel_columns()).difference(
        bagel.columns
    )

    if len(missing_req_columns) > 0:
        raise LookupError(
            f"The selected .csv is missing the following required metadata columns: {missing_req_columns}."
        )


def extract_pipelines(bagel: pd.DataFrame) -> dict:
    """Get data for each unique pipeline in the aggregate input as an individual labelled dataframe."""
    pipelines_dict = {}

    pipelines = bagel.groupby(["pipeline_name", "pipeline_version"])
    for (name, version), pipeline in pipelines:
        label = f"{name}-{version}"
        # per pipeline, rows are sorted in case participants/sessions are out of order
        pipelines_dict[label] = (
            pipeline.sort_values(["participant_id", "session"])
            .drop(["pipeline_name", "pipeline_version"], axis=1)
            .reset_index(drop=True)
        )

    return pipelines_dict


def check_num_subjects(bagel: pd.DataFrame):
    """Returns error if subjects and sessions are different across pipelines in the input."""
    pipelines_dict = extract_pipelines(bagel)

    pipeline_subject_sessions = [
        df.loc[:, ["participant_id", "session"]]
        for df in pipelines_dict.values()
    ]

    if not all(
        pipeline.equals(pipeline_subject_sessions[0])
        for pipeline in pipeline_subject_sessions
    ):
        raise LookupError(
            "The pipelines in bagel.csv do not have the same number of subjects and sessions."
        )


def get_overview(bagel: pd.DataFrame) -> pd.DataFrame:
    """
    Constructs a dataframe containing global statuses of pipelines in bagel.csv
    (based on "pipeline_complete" column) for each participant and session.
    """
    check_required_columns(bagel)
    check_num_subjects(bagel)

    pipeline_complete_df = bagel.pivot(
        index=["participant_id", "session"],
        columns=["pipeline_name", "pipeline_version"],
        values="pipeline_complete",
    )
    pipeline_complete_df.columns = [
        # for neatness, rename pipeline-specific columns from "(name, version)" to "{name}-{version}"
        "-".join(tup)
        for tup in pipeline_complete_df.columns.to_flat_index()
    ]
    pipeline_complete_df.reset_index(inplace=True)

    return pipeline_complete_df


app = Dash(
    __name__,
    external_stylesheets=["https://codepen.io/chriddyp/pen/bWLwgP.css"],
)


app.layout = html.Div(
    children=[
        html.H1(children="Neuroimaging Derivatives Status Dashboard"),
        dcc.Upload(
            id="upload-data",
            children=html.Button("Drag and Drop or Select .csv File"),
            style={"margin": "10px"},
            multiple=False,
        ),
        html.Div(id="output-data-upload"),
        dbc.Card(
            [
                # TODO: Put label and dropdown in same row
                html.Div(
                    [
                        dbc.Label("Filter by multiple sessions:"),
                        dcc.Dropdown(
                            id="session-dropdown",
                            options=[],
                            multi=True,
                            placeholder="Select one or more available sessions to filter by",
                        ),
                    ]
                ),
                html.Div(
                    [
                        dbc.Label("Selection operator:"),
                        dcc.Dropdown(
                            id="select-operator",
                            options=[
                                {
                                    "label": "AND",
                                    "value": "AND",
                                    "title": "Show only participants with all selected sessions.",
                                },
                                {
                                    "label": "OR",
                                    "value": "OR",
                                    "title": "Show participants with any of the selected sessions.",
                                },
                            ],
                            value="AND",
                            clearable=False,
                        ),
                    ]
                ),
            ]
        ),
    ]
)


def parse_csv_contents(
    contents, filename
) -> Tuple[Optional[pd.DataFrame], Optional[list], Optional[str]]:
    """
    Returns
    -------
    pd.DataFrame or None
        Dataframe containing global statuses of pipelines for each participant-session.
    list or None
        List of the unique session ids in the dataset.
    str or None
        Error raised during parsing of the input, if applicable.
    """
    content_type, content_string = contents.split(",")

    decoded = base64.b64decode(content_string)

    try:
        if ".csv" in filename:
            bagel = pd.read_csv(io.StringIO(decoded.decode("utf-8")))
        else:
            return None, None, "Input file is not a .csv file."
    except Exception as exc:
        print(exc)
        return None, None, "Something went wrong while processing this file."

    try:
        overview_df = get_overview(bagel=bagel)
    except LookupError as err:
        return None, None, str(err)

    sessions = overview_df["session"].sort_values().unique().tolist()
    # session_opts = [{"label": ses, "value": ses} for ses in sessions]

    return overview_df, sessions, None


def filter_by_sessions(
    data: pd.DataFrame, session_values: list, operator_value: str
) -> pd.DataFrame:
    """
    Returns dataframe filtered for data corresponding to the specified sessions, for participants
    who have either any or all of the selected sessions, depending on the specified operator.
    """
    if operator_value == "AND":
        matching_subs = []
        for sub_id, sub in data.groupby("participant_id"):
            if all(
                value in sub["session"].unique() for value in session_values
            ):
                matching_subs.append(sub_id)
        data = data[
            data["participant_id"].isin(matching_subs)
            & data["session"].isin(session_values)
        ]
    else:
        if operator_value == "OR":
            data = data[data["session"].isin(session_values)]

    return data


@app.callback(
    [
        Output("output-data-upload", "children"),
        Output("session-dropdown", "options"),
    ],
    [
        Input("upload-data", "contents"),
        State("upload-data", "filename"),
        Input("session-dropdown", "value"),
        Input("select-operator", "value"),
    ],
)
def update_outputs(contents, filename, session_values, operator_value):
    if contents is None:
        return html.Div("Upload a CSV file to begin."), []

    data, sessions, upload_error = parse_csv_contents(
        contents=contents, filename=filename
    )

    if upload_error is not None:
        return html.Div(f"Error: {upload_error} Please try again."), []

    if session_values:
        data = filter_by_sessions(
            data=data,
            session_values=session_values,
            operator_value=operator_value,
        )

    table = html.Div(
        [
            html.H5("Input file: " + filename),
            dash_table.DataTable(
                id="interactive-datatable",
                columns=[{"name": i, "id": i} for i in data.columns],
                data=data.to_dict("records"),
                sort_action="native",
                sort_mode="multi",
                filter_action="native",
                page_size=10,
            ),
            # TODO: Fix behaviour where session only allows filtering by strings
        ]
    )
    session_opts = [{"label": ses, "value": ses} for ses in sessions]

    return table, session_opts


@app.callback(
    Output("session-dropdown", "value"),
    Input("upload-data", "contents"),
    # prevent_initial_call=True ??
)
def reset_dropdowns(contents):
    """If file contents change (i.e., new CSV uploaded), reset session dropdown selection values."""
    if ctx.triggered_id == "upload-data":
        return ""
    raise PreventUpdate


if __name__ == "__main__":
    app.run_server(debug=True)
